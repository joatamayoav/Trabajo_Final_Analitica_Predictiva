{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default of Credit Card Clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n",
    "\n",
    "Content\n",
    "There are 25 variables:\n",
    "\n",
    "ID: ID of each client\n",
    "\n",
    "LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit\n",
    "\n",
    "SEX: Gender (1=male, 2=female)\n",
    "\n",
    "EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n",
    "\n",
    "MARRIAGE: Marital status (1=married, 2=single, 3=others)\n",
    "\n",
    "AGE: Age in years\n",
    "\n",
    "PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n",
    "\n",
    "PAY_2: Repayment status in August, 2005 (scale same as above)\n",
    "\n",
    "PAY_3: Repayment status in July, 2005 (scale same as above)\n",
    "\n",
    "PAY_4: Repayment status in June, 2005 (scale same as above)\n",
    "\n",
    "PAY_5: Repayment status in May, 2005 (scale same as above)\n",
    "\n",
    "PAY_6: Repayment status in April, 2005 (scale same as above)\n",
    "\n",
    "BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
    "\n",
    "BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
    "\n",
    "BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
    "\n",
    "BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
    "\n",
    "BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
    "\n",
    "BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
    "\n",
    "PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
    "\n",
    "PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
    "\n",
    "PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
    "\n",
    "PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
    "\n",
    "PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
    "\n",
    "PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
    "\n",
    "default.payment.next.month: Default payment (1=yes, 0=no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn\n",
    "!pip install joblib\n",
    "!pip install pydotplus\n",
    "!pip install pydot\n",
    "!pip install graphviz\n",
    "!pip install Pillow\n",
    "!pip install Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from datetime import datetime \n",
    "import time\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga Datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_excel(r'https://github.com/joatamayoav/Trabajo_Final_Analitica_Predictiva/blob/main/default_of_credit_card_clients.xls?raw=true',\n",
    "     header=1,\n",
    "    )\n",
    "\n",
    "df0.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.rename(columns=lambda x: x.lower(), inplace=True)\n",
    "df0.rename(columns={\"default payment next month\":\"default\"}, inplace=True) \n",
    "\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se crea copia del Dataframe original para no dañarlo\n",
    "#\n",
    "\n",
    "df = df0.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Dummys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable ficticia para explicar valores cualitativos en un modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grad_school'] = (df0[\"education\"] == 1).astype(int)\n",
    "df['university'] = (df0[\"education\"] == 2).astype(int)\n",
    "df['high_school'] = (df0[\"education\"] == 3).astype(int)\n",
    "df.drop(\"education\", axis = 1, inplace = True)\n",
    "\n",
    "df['male'] = (df0[\"sex\"] == 1).astype(int)\n",
    "df['female'] = (df0[\"sex\"] == 2).astype(int)\n",
    "df.drop(\"sex\", axis = 1, inplace = True)\n",
    "\n",
    "df['single'] = (df0[\"marriage\"] == 2).astype(int)\n",
    "df['married'] = (df0[\"marriage\"] == 1).astype(int)\n",
    "df.drop(\"marriage\", axis = 1, inplace = True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_features = ['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "\n",
    "for p in pay_features:\n",
    "    df.loc[df[p] <= 0, p] = 0\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de nulos\n",
    "\n",
    "total = df.isnull().sum().sort_values(ascending = False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending = False)\n",
    "pd.concat([total, percent], axis=1, keys=['Total', 'Percent']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[\"default\"].value_counts()\n",
    "\n",
    "df1 = pd.DataFrame({'default': temp.index,'values': temp.values})\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.title('Default Credit Card Clients - target value - data unbalance\\n (Default = 0, Not Default = 1)')\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x = 'default', y=\"values\", data=df1)\n",
    "\n",
    "locs, labels = plt.xticks()\n",
    "\n",
    "plt.show()\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución Credit Limit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,6))\n",
    "plt.title('Amount of credit limit - Density Plot')\n",
    "sns.set_color_codes(\"dark\")\n",
    "sns.distplot(df['limit_bal'],kde=True,bins=200, color=\"black\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "temp = df[\"limit_bal\"].value_counts()\n",
    "df1 = pd.DataFrame({'limit_bal': temp.index,'values': temp.values})\n",
    "\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importación de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixConfusion(cm, labels = ['pay','default']):\n",
    "    df = pd.DataFrame(data=cm, index=labels , columns=labels)\n",
    "    df.index.name = 'True'\n",
    "    df.columns.name = 'Prediction'\n",
    "    df.loc['Total'] = df.sum()\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Greys):\n",
    "    plt.figure(figsize=(9, 3), dpi = 72, tight_layout = True)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=0)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks()+1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.0f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')  \n",
    "    plt.show()\n",
    "    \n",
    "# ;\n",
    "\n",
    "#     plt.figure(figsize=(8, 10))\n",
    "#     sns.heatmap(mc, annot=True, fmt=\"d\");\n",
    "#     plt.title(\"Confusion matrix\")\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(index=['accuracy', 'precision', 'recall', 'roc_auc_score'],\n",
    "                       columns=['BernoulliNB', 'GaussianNB'])\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de entrenamiento y prueba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'default'\n",
    "\n",
    "X = df.drop('default', axis = 1)\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "X = robust_scaler.fit_transform(X)\n",
    "\n",
    "Y = df[target]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.15, random_state=123, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se importa la libreria\n",
    "#\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#\n",
    "# Se crea un clasificador Gaussiano ingenuo\n",
    "#\n",
    "gnb = BernoulliNB(\n",
    "    alpha=1.0,        # Laplace parameter\n",
    "    binarize=0.0,\n",
    "    fit_prior=True,\n",
    "    class_prior=None,\n",
    ")\n",
    "\n",
    "#\n",
    "# Se entrena el clasificador\n",
    "#\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "#\n",
    "# Se pronostica la clasificación de los\n",
    "# mensajes para los datos de entrada\n",
    "#\n",
    "y_pred_test = gnb.predict(X_test)\n",
    "\n",
    "#\n",
    "# Evaluación\n",
    "#\n",
    "\n",
    "metrics.loc['accuracy','BernoulliNB'] = accuracy_score(y_pred=y_pred_test, y_true=Y_test)\n",
    "metrics.loc['precision','BernoulliNB'] = precision_score(y_pred=y_pred_test, y_true=Y_test)\n",
    "metrics.loc['recall','BernoulliNB'] = recall_score(y_pred=y_pred_test, y_true=Y_test)\n",
    "metrics.loc['roc_auc_score','BernoulliNB'] = roc_auc_score(y_pred_test, Y_test)\n",
    "\n",
    "#\n",
    "# Matriz Confusión\n",
    "#\n",
    "\n",
    "cm = confusion_matrix(y_pred=y_pred_test, y_true=Y_test)\n",
    "matrix = MatrixConfusion(cm)\n",
    "print(matrix)\n",
    "print()\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "#\n",
    "# Reporte\n",
    "#\n",
    "\n",
    "sk_report = classification_report(\n",
    "    digits=4,\n",
    "    y_true=Y_test, \n",
    "    y_pred=y_pred_test)\n",
    "print(sk_report)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
